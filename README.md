<div align="center">
  <img src="LOGO.png" alt="OptimaX Logo" width="200"/>

  # OptimaX - Intelligent SQL Chat Application

  **AI-Powered Natural Language to SQL with 100% Local Execution**

  [![Angular](https://img.shields.io/badge/Angular-20.3-DD0031?logo=angular)](https://angular.io/)
  [![FastAPI](https://img.shields.io/badge/FastAPI-0.104-009688?logo=fastapi)](https://fastapi.tiangolo.com/)
  [![Python](https://img.shields.io/badge/Python-3.10+-3776AB?logo=python)](https://www.python.org/)
  [![PostgreSQL](https://img.shields.io/badge/PostgreSQL-14+-336791?logo=postgresql)](https://www.postgresql.org/)
  [![Ollama](https://img.shields.io/badge/Ollama-Local_LLM-000000)](https://ollama.ai/)

</div>

---

## ğŸ“– About OptimaX

OptimaX is an intelligent SQL chat application that allows users to query traffic accident data using natural language. Built with modern web technologies and powered by local LLMs, it delivers fast, secure, and privacy-focused database interactions without any cloud dependencies.

### ğŸ¯ Key Features

- **Natural Language Queries** - Ask questions in plain English, get SQL results
- **100% Local Execution** - All AI processing runs locally via Ollama (no cloud APIs)
- **Lightning Fast** - 70-80% faster with heuristic routing and multi-level caching
- **Modern Glass UI** - Beautiful glass morphism design with smooth animations
- **Real-time Charts** - Automatic chart detection and visualization
- **Developer Tools** - Built-in debug panel with SQL query inspection
- **Smart Routing** - Heuristic pattern matching for 60-80% of queries
- **Multi-level Cache** - Intelligent caching system (99.6% faster for cached queries)

### ğŸ“Š Dataset

- **7.7+ Million US Traffic Accident Records** (2016-2023)
- Geographic data (state, city, coordinates)
- Weather conditions (temperature, visibility, precipitation)
- Severity levels (1-4 scale)
- Road features (traffic signals, junctions, crossings)

**Data Source:** [US Accidents Dataset on Kaggle](https://www.kaggle.com/datasets/sobhanmoosavi/us-accidents)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OptimaX Architecture                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  Frontend (Angular 20)                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ â€¢ Glass Morphism UI                                 â”‚    â”‚
â”‚  â”‚ â€¢ Chart.js Visualization                            â”‚    â”‚
â”‚  â”‚ â€¢ Real-time Chat Interface                          â”‚    â”‚
â”‚  â”‚ â€¢ Developer Debug Panel                             â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                  â”‚
â”‚                           â†“ HTTP/REST                        â”‚
â”‚                                                               â”‚
â”‚  Backend (FastAPI + Python)                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Heuristic Router (60-80% hit rate)                  â”‚    â”‚
â”‚  â”‚         â†“                                            â”‚    â”‚
â”‚  â”‚ Async Inference Engine                              â”‚    â”‚
â”‚  â”‚         â†“                                            â”‚    â”‚
â”‚  â”‚ Query Cache (Multi-level)                           â”‚    â”‚
â”‚  â”‚         â†“                                            â”‚    â”‚
â”‚  â”‚ Local LLM (Ollama)                                  â”‚    â”‚
â”‚  â”‚   â€¢ Phi-3 Mini (Intent Routing)                     â”‚    â”‚
â”‚  â”‚   â€¢ Qwen2.5-Coder 3B (SQL Generation)              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                  â”‚
â”‚                           â†“ SQL                              â”‚
â”‚                                                               â”‚
â”‚  Database (PostgreSQL)                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ 7.7M+ Accident Records                              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start Guide

### Prerequisites

Before you begin, ensure you have the following installed:

- **Node.js** 18+ and npm ([Download](https://nodejs.org/))
- **Python** 3.10+ ([Download](https://www.python.org/downloads/))
- **PostgreSQL** 14+ ([Download](https://www.postgresql.org/download/))
- **Ollama** ([Download](https://ollama.ai/))
- **Git** ([Download](https://git-scm.com/))

### Step 1: Clone the Repository

```bash
git clone <your-repository-url>
cd OptimaX
```

### Step 2: Setup Database

#### 2.1 Create PostgreSQL Database

```bash
# Open PostgreSQL command line
psql -U postgres

# Create database
CREATE DATABASE traffic_db;

# Exit psql
\q
```

#### 2.2 Load Database Schema

```bash
# Load the schema
psql -U postgres -d traffic_db -f create_accidents_table.sql
```

#### 2.3 Import Dataset

1. Download the US Accidents dataset from [Kaggle](https://www.kaggle.com/datasets/sobhanmoosavi/us-accidents)
2. Extract the CSV file
3. Import data into PostgreSQL:

```bash
# Using psql COPY command
psql -U postgres -d traffic_db

# Inside psql:
\COPY accidents FROM 'path/to/US_Accidents.csv' DELIMITER ',' CSV HEADER;
```

**Note:** Import may take 30-60 minutes depending on your system.

### Step 3: Setup Backend

#### 3.1 Navigate to Backend Directory

```bash
cd sql-chat-backend
```

#### 3.2 Install Python Dependencies

```bash
# Using pip
pip install -r requirements.txt

# Or using a virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

#### 3.3 Configure Environment Variables

Create a `.env` file in the `sql-chat-backend` directory:

```bash
# .env file
DATABASE_URL=postgresql://postgres:your_password@localhost:5432/traffic_db
OLLAMA_BASE_URL=http://localhost:11434
```

**Replace `your_password` with your PostgreSQL password.**

#### 3.4 Pull Required Ollama Models

```bash
# Pull Phi-3 Mini for intent routing
ollama pull phi3:mini

# Pull Qwen2.5-Coder for SQL generation
ollama pull qwen2.5-coder:3b
```

**Note:** First-time model downloads may take 5-15 minutes depending on your internet speed.

#### 3.5 Start Backend Server

```bash
# Start the optimized backend
python main_optimized.py

# Or start the original backend
python main.py
```

Backend will be available at: `http://localhost:8002`

### Step 4: Setup Frontend

#### 4.1 Open New Terminal and Navigate to Frontend

```bash
cd sql-chat-app
```

#### 4.2 Install Node Dependencies

```bash
npm install
```

**Note:** Installation may take 2-5 minutes.

#### 4.3 Start Development Server

```bash
ng serve

# Or use npm
npm start
```

Frontend will be available at: `http://localhost:4200`

### Step 5: Access the Application

1. Open your browser and navigate to `http://localhost:4200`
2. Wait for the initialization sequence to complete
3. Start chatting with your database!

---

## ğŸ’» Usage Examples

### Example Queries

Try these natural language queries:

#### Geographic Analysis
```
"Show me the top 10 states with the most accidents"
"Which city has the most accidents?"
"Find accidents in California"
"Compare accidents in Texas vs Florida"
```

#### Weather Analysis
```
"Show accidents during rain weather"
"Which weather conditions cause the most accidents?"
"Find accidents with visibility less than 2 miles"
```

#### Severity Analysis
```
"Count accidents by severity level"
"Show me severe accidents in New York"
"What percentage of accidents are severity 4?"
```

#### Temporal Analysis
```
"Show accidents by month in 2021"
"What time of day has the most accidents?"
"Compare morning vs evening accidents"
```

---

## ğŸ› ï¸ Technology Stack

### Frontend
- **Framework:** Angular 20.3
- **Language:** TypeScript 5.9
- **Styling:** SCSS with Glass Morphism
- **Charts:** Chart.js + ng2-charts
- **HTTP Client:** RxJS + Angular HttpClient

### Backend
- **Framework:** FastAPI 0.104.1
- **Language:** Python 3.10+
- **LLM Framework:** llama-index 0.10.68
- **Async HTTP:** aiohttp 3.9.1
- **Database ORM:** SQLAlchemy 2.0.23
- **Database Driver:** psycopg2-binary 2.9.9

### Database
- **DBMS:** PostgreSQL 14+
- **Records:** 7.7+ Million
- **Size:** ~2.5GB

### AI/ML
- **LLM Runtime:** Ollama (Local)
- **Intent Router:** Phi-3 Mini (3.8B parameters)
- **SQL Generator:** Qwen2.5-Coder (3B parameters)

---

## ğŸ“Š Performance

### Response Times

| Query Type | Before Optimization | After Optimization | Improvement |
|------------|-------------------|-------------------|-------------|
| Cached Query | 2500ms | 5-10ms | **99.6% faster** âš¡âš¡âš¡ |
| SQL (Heuristic) | 3000ms | 600ms | **80% faster** âš¡âš¡ |
| SQL (LLM) | 3500ms | 1200ms | **66% faster** âš¡ |
| Chat (Cached) | 2000ms | 5-10ms | **99.5% faster** âš¡âš¡âš¡ |

### Key Metrics
- **Heuristic Hit Rate:** 60-80%
- **Cache Hit Rate:** 60-80% (after warmup)
- **LLM Call Reduction:** 60-80%
- **Throughput Increase:** 3-5x

---

## ğŸ“ Project Structure

```
OptimaX/
â”œâ”€â”€ sql-chat-app/                    # Angular Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chat-interface/       # Main chat UI
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chart-visualization/  # Chart rendering
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ system-prompt-manager/# Prompt editor
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ loading-screen/       # Loading animation
â”‚   â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚   â”‚       â”œâ”€â”€ chat.service.ts       # API communication
â”‚   â”‚   â”‚       â””â”€â”€ chart-detection.service.ts
â”‚   â”‚   â””â”€â”€ styles.scss                   # Global styles
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ angular.json
â”‚
â”œâ”€â”€ sql-chat-backend/                # FastAPI Backend
â”‚   â”œâ”€â”€ main_optimized.py            # â­ Optimized backend
â”‚   â”œâ”€â”€ main.py                      # Original backend
â”‚   â”œâ”€â”€ heuristic_router.py          # Smart routing engine
â”‚   â”œâ”€â”€ async_inference.py           # Async LLM inference
â”‚   â”œâ”€â”€ query_cache.py               # Multi-level caching
â”‚   â”œâ”€â”€ test_optimizations.py        # Test suite
â”‚   â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚   â”œâ”€â”€ .env                         # Environment config
â”‚   â”œâ”€â”€ QUICK_START.md              # Setup guide
â”‚   â”œâ”€â”€ OPTIMIZATION_GUIDE.md        # Detailed docs
â”‚   â””â”€â”€ BENCHMARKS.md               # Performance data
â”‚
â”œâ”€â”€ create_accidents_table.sql       # Database schema
â”œâ”€â”€ LOGO.png                         # Application logo
â”œâ”€â”€ OPTIMIZATION_SUMMARY.md          # Optimization overview
â””â”€â”€ README.md                        # This file
```

---

## ğŸ”§ Configuration

### Backend Configuration

Edit `sql-chat-backend/.env`:

```env
# Database connection
DATABASE_URL=postgresql://user:password@host:port/database

# Ollama configuration
OLLAMA_BASE_URL=http://localhost:11434

# Server configuration (optional)
HOST=0.0.0.0
PORT=8002
DEBUG=false
```

### Frontend Configuration

Edit `sql-chat-app/src/environments/environment.ts`:

```typescript
export const environment = {
  production: false,
  apiUrl: 'http://localhost:8002'
};
```

### Optimization Tuning

Adjust cache sizes and TTL in `sql-chat-backend/query_cache.py`:

```python
# Configure cache parameters
cache = get_query_cache(
    max_size=1000,      # Max cached entries
    default_ttl=3600    # 1 hour TTL
)
```

---

## ğŸ§ª Testing

### Run Backend Tests

```bash
cd sql-chat-backend
python test_optimizations.py
```

Tests include:
- âœ… Heuristic router accuracy (80-90%)
- âœ… Async inference performance
- âœ… Cache hit rate validation
- âœ… End-to-end query processing

### Run Frontend Tests

```bash
cd sql-chat-app
ng test
```

---

## ğŸ“ˆ Monitoring

### Performance Metrics Endpoint

```bash
# Get real-time performance metrics
curl http://localhost:8002/performance
```

**Response:**
```json
{
  "total_requests": 1000,
  "heuristic_routing": {
    "hits": 750,
    "percentage": 75.0
  },
  "cache_stats": {
    "hit_rate": 0.72,
    "total_entries": 250
  },
  "response_times": {
    "average_ms": 650
  }
}
```

### Continuous Monitoring

```bash
# Monitor performance continuously
watch -n 5 'curl -s http://localhost:8002/performance | jq'
```

---

## ğŸ› Troubleshooting

### Common Issues

#### 1. Backend Won't Start

**Error:** `ModuleNotFoundError: No module named 'X'`

**Solution:**
```bash
pip install -r requirements.txt
```

#### 2. Database Connection Failed

**Error:** `could not connect to server: Connection refused`

**Solution:**
- Verify PostgreSQL is running: `pg_ctl status`
- Check `.env` file has correct credentials
- Test connection: `psql -U postgres -d traffic_db`

#### 3. Ollama Models Not Found

**Error:** `model 'phi3:mini' not found`

**Solution:**
```bash
ollama pull phi3:mini
ollama pull qwen2.5-coder:3b
```

#### 4. Frontend Build Errors

**Error:** `An unhandled exception occurred: Cannot find module '@angular/...'`

**Solution:**
```bash
rm -rf node_modules package-lock.json
npm install
```

#### 5. Slow Response Times

**Issue:** Queries taking >5 seconds

**Solution:**
- Check cache hit rate: `curl http://localhost:8002/performance`
- Ensure Ollama is running: `ollama list`
- Verify database indexes exist
- Monitor system resources (CPU/RAM)

---

## ğŸ“š API Documentation

### Core Endpoints

#### POST `/chat`
Send a chat message and get SQL results

**Request:**
```json
{
  "message": "Show me accidents in California"
}
```

**Response:**
```json
{
  "response": "Found 1,234,567 accidents in California",
  "sql_query": "SELECT COUNT(*) FROM accidents WHERE state = 'CA'",
  "data": [...]
}
```

#### GET `/performance`
Get real-time performance metrics

#### GET `/health`
Health check endpoint

#### GET `/table-info`
Get database schema information

### System Prompt Endpoints

#### GET `/system-prompts`
Get current system prompts

#### POST `/system-prompts`
Update system prompts

#### POST `/system-prompts/reset`
Reset prompts to defaults

---

## ğŸš¢ Deployment

### Production Build

#### Frontend
```bash
cd sql-chat-app
ng build --configuration production
```

Output will be in `dist/sql-chat-app/`

#### Backend
```bash
cd sql-chat-backend
uvicorn main_optimized:app --host 0.0.0.0 --port 8002 --workers 4
```

### Docker Deployment (Optional)

Coming soon! Docker Compose configuration for easy deployment.

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is for educational and demonstration purposes.

**Dataset License:** [US Accidents Dataset](https://www.kaggle.com/datasets/sobhanmoosavi/us-accidents) - Check Kaggle for license details.

---

## ğŸ™ Acknowledgments

- **Ollama** - Local LLM inference platform
- **Anthropic** - Claude for development assistance
- **Angular Team** - Excellent frontend framework
- **FastAPI** - Modern Python web framework
- **Sobhan Moosavi** - US Accidents dataset creator
- **Kaggle** - Dataset hosting platform

---

## ğŸ“ Support

### Documentation
- [Quick Start Guide](sql-chat-backend/QUICK_START.md)
- [Optimization Guide](sql-chat-backend/OPTIMIZATION_GUIDE.md)
- [Performance Benchmarks](sql-chat-backend/BENCHMARKS.md)
- [Optimization Summary](OPTIMIZATION_SUMMARY.md)

### Need Help?
1. Check documentation files
2. Run test suite: `python test_optimizations.py`
3. Review performance metrics: `curl http://localhost:8002/performance`
4. Check application logs

---

## ğŸ‰ Success Indicators

You're ready when you see:
- âœ… Backend starts without errors
- âœ… Frontend loads at `http://localhost:4200`
- âœ… Test suite passes (80-90% accuracy)
- âœ… Heuristic hit rate >60%
- âœ… Average response time <1000ms
- âœ… Charts rendering correctly
- âœ… No database connection errors

---

<div align="center">

**Version:** 2.0.0 (Optimized)
**Status:** âœ… Production Ready
**Performance:** 70-80% faster than v1.0
**Privacy:** 100% Local (No cloud dependencies)

**Built with â¤ï¸ using Angular, FastAPI, and Ollama**

[â¬† Back to Top](#optimax---intelligent-sql-chat-application)

</div>
